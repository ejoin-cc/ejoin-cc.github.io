---
title: 分布式系统的概念
---
# 分布式系统的概念

本节中，我们先来简单了解一下什么是分布式系统、为什么需要分布式系统以及简单的讨论下分布式系统需要解决哪些问题。为以后的学习构建一个基础脉络。

## 单机的限制

当今的数字世界中，我们的大部分活动都依赖于网络服务。无论是点餐系统还是金融理财，这些服务都是在某个服务器上运行并处理用户请求的。这些服务器使用 CPU、内存、网络和磁盘来存储数据、处理用户请求并执行一些行为。这四种基本的物理资源对于任何服务器来说都是必不可少的，单个服务器处理用户请求的能力最终取决于这四种物理资源的限制。

随着互联网的发展，用户数目和用户请求量越来越大，单个服务器需要处理的请求数变多，此时就产生了问题：当服务器的资源利用率达到极限时，系统的总吞吐量反而会受到影响。例如当 CPU 或内存使用率接近极限时，新增的用户请求必须排队等待资源调度，随着越来越多的请求堆积，等待时间增加，服务器不能有效处理用户请求，总吞吐量降低。即我们期望服务器能够处理越来越多的请求，但实际上服务器总体性能会下降。

此时一种很简单直观的解决方式是增加单服务器的物理资源，但由于摩尔定律失效，廉价服务器的性能瓶颈无法继续突破，使用大容量服务器的成本很难降低。

另一种解决方式是：在多个服务器上划分和处理不同的用户请求，这样就可以充分利用单独的 CPU、内存、网络和磁盘等资源。

单机系统的另一个问题在于当进程崩溃时，所有的请求都无法被处理，即有单点失效问题。

## 分离计算层和存储层

为了解决单机资源受限的问题，一种常见的划分方式是将服务拆分为两部分，一部分是无状态组件（计算层），负责直接向用户提供功能，执行一些计算逻辑，如 Web 应用或者 Web API 等，计算层不依赖于服务器本地的特定数据。另一部分是有状态组件（存储层），一般由数据库管理。

<div align=center>
<img width="500" src="./images/dist_intro_01.png"/>
</div>

我们可以将这两部分部署在单独的服务器上，使用单独的物理资源来处理请求。如果处理大多数用户请求所需的数据都可以在计算层的缓存中获取，只有一小部分请求需要通过计算层访问存储层时，这种架构的表现特别好：此时大多数请求都可以在计算层被处理，由于它不需要依赖于特定数据，我们直接添加计算层服务器就可以适应不断增长的用户群，确保请求能够被有效处理。

<div align=center>
<img width="500" src="./images/dist_intro_02.png"/>
</div>

这种方法对于大多数应用程序来说都是有效的。但当数据库（存储层）中的数据量增长到数百 TB 甚至 PB 级，或者需要存储层参与处理的请求数量显著增加时，存储层的服务器就成为了瓶颈。即这种简单架构的处理能力受到存储层的服务器的四种基本资源的限制。

> 计算层可以继续拆分，例如可以将计算层按照不同的逻辑拆分为多个子系统部署在不同服务器上。处理请求时可以将单个请求拆分为对多个不同子系统的请求，并在不同的服务器上并行执行。

## 数据分区

和之前的思路类似，当存储层服务器受到物理资源限制时，我们同样考虑拆分。一种方法是将数据拆分存储在多个服务器上，这样可以利用单独的 CPU、网络、内存和磁盘来分别处理较小数据集上的请求。

<div align=center>
<img width="500" src="./images/dist_intro_03.png"/>
</div>

## 引入的新问题

我们目前使用多个服务器来解决单机面临的资源限制的问题，但此时也引入了新的问题，我们先简单概括一下，一些概念和细节将在后面进行讨论。

在此前的讨论中，可以看到一个请求很可能需要多个服务器节点协同工作才能被正确处理。我们需要考虑多个服务器之间如何通信并协调的。一般来说集群中通信的双方负责不同功能，常用的方式是将多个服务器根据不同功能划分为不同的集群（每个集群对应一个服务），集群之间可以通过服务注册和发现来确认要通信的服务包含哪些服务器实例。

找到服务之后如何确认要与哪个实例进行通信呢？如果该服务中的各个实例状态完全相同（无状态），简单的随机选择或者使用负载均衡策略（轮询、权重等）选择一个实例进行通信就可以；如果服务中的各实例状态不同（有状态），那么就需要通过其他元数据先确定当请求所需的信息保存在哪一个实例上，然后再进行访问。确定对端实例后，可以使用 RPC 协议或者 HTTP 协议进行通信。

多个服务器节点（集群）的管理也是一个问题。我们希望可以灵活增加节点或者删除节点来应对请求数目增加或者减少的情况。一种方式是通过配置文件（存储集群元数据）来管理集群，但手动管理配置文件低效且容易出错，我们需要自动化的方式，常用的是通过一个中心化的存储来统一管理配置，即配置中心。

如果多个计算层节点分别处理不同的请求，这些请求试图修改同一条数据记录，如何处理多节点的资源竞争问题？在单机系统中，直接使用普通锁机制就可以处理并发问题。但分布式场景下，普通的锁无法让另一个节点感知到临界资源已经被其他节点占领，无法满足数据一致性要求，对于这个问题我们通过使用分布式锁来解决。

和锁机制类似，在单机系统中，事务可以简单的通过日志实现，当并发事务冲突时，可以通过时间戳或事务号简单的确定哪个事务可以正确提交，哪个事务需要回滚。在分布式集群中，多个机器的时间戳可能并不同步，我们需要特殊的机制来实现分布式事务。

使用服务器集群时，故障就成为了一个重要的话题。即使单个设备故障的概率很低，但当设备数目足够多，一天内至少有一个设备故障的概率也很高，而故障可能会导致严重的问题，在上一节数据分区架构中，如果某个存储数据的服务器磁盘故障了，它保存的那部分数据子集都不可用，对应的请求都会失败，直到磁盘数据恢复。目前的几乎所有业务场景都需要保证业务可用性，我们不希望某个服务器故障就导致所有对应的请求都无法被处理。为了保证分布式系统在某些节点故障时仍能提供服务，此前讨论的数据分区模式是不够的，我们需要额外的方式来屏蔽故障。

计算层（无状态）服务器故障的处理比较容易，由于无状态计算不依赖存储在服务器本地的特定数据，因此任何服务器都可以处理来自任何用户的请求（而无需事先加载特定的数据）。所以我们可以简单的将故障服务器上的请求重定向到另一台服务器或者添加一个新的服务器来接管工作负载即可。

存储层服务器的故障处理很有挑战性，由于每个服务器有特定的状态，所以服务器需要更多的机制和策略确保服务器以正确的状态启动，并需要与其他节点协调以避免提供错误或老旧的数据，我们也将重点讨论这类问题。

复制在屏蔽故障和确保服务可用性方面起着至关重要的作用。如果我们将数据在多台服务器上进行备份，即使发生了故障，客户端也可以连接到保存了数据副本的服务上从而获得数据。但实现这一点并不像听起来那么简单。屏蔽故障需要由处理用户请求的软件来完成，软件必须要能够检测到故障，并确保用户不会看到因故障引起的不一致的内容。下面让我们简单讨论下软件系统可能遇到的故障类型，这些故障都需要由软件系统进行屏蔽。

**进程崩溃**：软件进程可能会由于各种各样的原因而意外崩溃。可能是硬件故障或者代码中未经处理的异常造成的。在容器化或云环境中，监控软件可以自动重启被识别为故障的进程。假如用户发起请求期望在服务器上存储数据，并且服务器已经返回请求处理成功的响应，确保进程在重启后用户期望保存的数据仍然可用是十分重要的，我们需要采取措施来处理进程崩溃并确保数据的完整性和可用性。

需要注意的是，节点故障可能会导致雪崩，雪崩通常是由于整个系统中一部分实例出现故障，进而导致系统其他实例也故障导致的。例如系统中某个计算层服务器故障，原本由该实例处理的请求被划分到其他实例上处理，导致其他实例由于负载升高又触发了故障，一直恶性循环最终整个集群崩溃。要想避免这种雪崩问题可以从两个方面进行，一种是快速减少系统负载（通过快速失败和降级机制），另一种是快速增加系统处理请求的能力（通过弹性扩容机制）。

**网络问题**：TCP/IP 网络协议是异步的，它不保证消息传递的延迟。使用 TCP/IP 通信的软件进程必须确定等待其他进程响应的超时时间，如果在指定的时间内没有收到响应，它们需要决定是继续重试还是标记其他进程已经故障。

另一个问题是，如果客户端的一个请求处理成功，但由于网络问题客户端未收到处理成功的响应，客户端触发了重试策略，此时一个请求的操作可能会被多次执行，如果请求对应的操作是非幂等的，会导致数据不一致。当节点由于网络连接波动收到逻辑上已过期的消息时情况会更加复杂，我们需要一些机制，使得对于节点收到的每条消息，可以根据某些信息来决定是忽略还是处理这些消息。

**时钟问题**：不同服务器上的时钟时间可能不同。即使有 NTP 这样的服务，网络故障等问题也可能导致服务器上的时钟不同步，当进程需要排序消息或确定保存数据的顺序时，不能依赖于系统时间戳，因为服务器之间的时钟可能不一致。

## 分布式系统

到这里我们已经对分布式系统有了一个基本的了解了。在继续之前，我们为分布式系统建立一个定义。

「分布式系统」是一种软件架构，它由多个相互连接的节点或服务器组成，这些节点通过网络互相通信并协同工作，提供统一的可扩展的环境以实现一个共同的目标，

在分布式系统中，工作负载分布在多个服务器上，允许它们并行处理以提高性能。系统旨在处理大量数据，容纳大量并发用户。它通过划分数据提供并行处理能力，通过跨多个节点复制数据和服务来提供容错和弹性，确保系统即使在出现故障或网络中断的情况下也能保持正常运行。